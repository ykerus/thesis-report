
\section{Recurrent Neural Network (RNN)}
\red{[TODO]}

\subsection{Application to exoplanets}
In a task that resembles detection, \cite{hinners2018machine} compared a bi-LSTM with a feature engineering approach. Among other tasks, the task was to predict the number of transits present in a given light curve. Their bi-LSTM model produced near-random results. Other tasks included the prediction of parameters of the star given its light curve. They address the problem of the RNN-based model could be due to the fact that their data set was imbalanced. However, we note that it might have been due to the sparse learning signal that is given to the RNN. Namely, only after having seen about 7000 input data points, the RNN receives one learning signal over its single output value. This way, figuring out where transit signals are present in a given light curve can only be implicitly learned by the model, while we can also explicitly provide this information as learning signal at every time step. This idea has motivated us to develop the RNN-based transit detection algorithm presented in this work, which is further described in Chapter \ref{chap:methodology}. 

In another work utilizing LSTMs, \cite{morvan2020detrending} show the successful application of LSTMs for detrending. The model was trained to learn out-of-transit patterns, and interpolate these within the duration of a given transit signal. By doing so, the background signal could be better subtracted from the signal, and thus the transiting planet better characterized. Results improved if centroid data was included.

\subsection{Application to variable stars}
Remaining literature mostly focuses on light curve classification, in general for variable stars. For example, \cite{jamal2020neural} compare different neural network architecture for this task, including dilated temporal convolutional networks (dTCNs), LSTMs, GRUs, temporal convolutional NNs (tCNNs) and encoder-decoder models. The LSTM and tCNN were found to be performing best, with the latter having the benefit of shorter computation times. 

\cite{naul2018recurrent} address the problem of irregularly sampled data in light curves by including time intervals between measurement as input to an RNN encoder. The RNN is used for variable star classification. \cite{becker2020scalable} also experiments with time intervals between measurements as input to the model, and instead of using the raw flux they also use the differences between subsequent flux values as input. To reduce computational requirements, they adopted a sliding window approach over the input light curve, of which each window is used seperately to train the RNN. While most works employ a bidirectional RNN, in this work a unidirectional RNN was used to allow for its application in an online fashion.

% \cite{tsang2019deep} jointly train an RNN with an autoenconder to reconstruct and classify variable star light curves. They use a Gaussian mixture model to detect novel light curves.

\subsection{Anomaly detection}
Transit signals can be seen as anomalies in time series of ``normal'' stellar behaviour. LSTMs have been used to detect anomalies in time series in an unsupervised learning approach by \cite{malhotra2015long}. In this case, the LSTM is trained to predict the normal data and the errors on the predictions are used to threshold the detection of an anomalous event. If the LSTM is trained to predict multiple steps into the future, the same approach can be used to detect collective anomalies \citep{bontemps2016collective}, for example transit signals which generally cover multiple data points. However, as \cite{cherdo2020training} noted, this `unsupervised' approach to using LSTMs for anomaly detection still requires training on normal data, i.e. we need to know beforehand which data is clear of anomalous events. In our case, we might never be fully sure to whether a light curve is clear of transit signals, e.g. small and previously unseen signals might still be hidden in the data. Training the model to treat these light curves as ``normal'' data, might seriously harm the ability of the model to detect the smallest transit signals. For our purposes, we therefore turn to the supervised approach, as we can utilize both the transit signals from known exoplanets as well as realistically simulated signals as inputs to our model. 

\subsection{Irregularly-sampled time series}
Although attempts have been made to handle irregularly sampled time series using RNNs for variable star classificiation, developments within AI can provide different perspectives on the problem. Not related to variable stars but related to handling irregular time series using RNNs, is the ODE-RNN \cite{rubanova2019latent}. This model design, inspired by \cite{chen2018neural}, treats time as continuous, whereas the standard RNN treats time as discrete steps. The ODE-RNN can handle arbitrary time gaps between observations, which could be useful for our purposes. However, this comes at the cost of a required altering of the training process as opposed to using a standard RNN, in which batched training does not come straightforward. Moreover, the benefits of the ODE-RNN are most profound if the sampled data is sparse. With transit durations in the order of hours and a observation cadence in the order of minutes, this is generally not the case. For this reason, we rely on the standard RNN architectures in this work, and leave the application of ODE-RNNs for exoplanet science for future work.