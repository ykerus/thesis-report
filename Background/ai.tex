
\section{Other relevant work in AI}
\todo{write section introduction, and extend on the subsections;  make the flow more natural, and include more related work}

\subsection{Uncertainty in neural networks}
Although the topic of uncertainty can be a thesis subject on its own, we briefly touch on the subject as uncertainties could play a role in the task of transit detection. For example, if multiple candidate transit signals are detected and detector's response is similar for all, we might wish to accept only the signals for which the detection uncertainty is below a certain threshold. For neural networks, though in some cases their output has some probabilistic meaning, in general one must be cautious with interpreting their outputs as probability. If unseen out-of-distribution data is presented to the network, which differs substantially from the training data, its outputs might not make sense anymore. \red{[TODO: explain: why would out of dist data occur?]} Instead, it would be convenient if the network outputs an additional value that indicates the confidence of a certain classification. 

\cite{gal2016dropout} describe how dropout with repeated application of the network can be used to obtain uncertainty estimates over predictions. Although this approach is appealingly simple, a few problems remain. First of all, this approach might not solve the problem, because for each instance of the model the data would remain out-of-distribution, and might trigger an erroneous detection in each case with low uncertainty as a result. Furthermore, as RNNs are already less efficient than for example CNNs, the need for repeated application might harm their scalability considerably. Obtaining reliable uncertainty estimates for RNNs is not a straightforward task. Work on uncertainty estimation for RNNs is still being published \citep{alaa2020frequentist, hwang2020sampling, wang2020uncertainty}. For our purposes, we use the method proposed by \cite{devries2018learning} and explore it for our task. Their approach is to adjust the loss function that is used for training, such that the network learns for which inputs it is more certain of its outputs and vice versa. The details and integration of this method in combination with our RNN is described in Chapter \ref{chap:methodology}.

% \cite{le2020contrastive} describes the contrastive learning framework.

% \cite{he2009learning} describe ways to deal with imbalanced data sets.

% Exploding gradients in GRUs are known to be a problem \cite{kanai2017preventing}.