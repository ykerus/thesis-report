
\section{Answers to research questions}

Although this work is based on simulated data, the results achieved on both LCSim and Lilith data show that RNNs have promising capability of performing well in the task of transit detection. The question of how RNNs should be applied for this task was investigated in several experiments. Different preprocessing steps were evaluated, involving for example the way data gaps are handled and the way input data is scaled. Although RNNs come with the possibility of predicting missing values in a light curve, we found that a simple gap-filling approach such as linear interpolation can lead to similar results, while requiring less computation time. Furthermore, it was shown that zero-filling gaps in Lilith data can result in better performance of the RNN, compared to using linear interpolation. Possibly, zero-filling allows the network to better distinguish imputed data points from real ones, such that it takes into account the fact that they were missing from the original light curve. In literature concerning transit detection, the effect of missing data on the performance of neural networks was only touched upon by \cite{pearson2018searching}, however no methods were evaluated to deal with this problem. In the task of light curve classification, \cite{naul2018recurrent} and \cite{becker2020scalable} provide the differences between sampling times as input to an RNN to deal with data gaps. This approach has yet to be evaluated in the task of transit detection.

Regarding the scaling of light curves prior to applying the RNN, we expected that scaling light curves by their estimated white noise level would be beneficial to the network. Namely, we would argue that by removing the variance in white noise, the transit signal would stand out more. However, the results showed that this sort of scaling, which we referred to as sigma scaling, was only beneficial for the deepest transit signals in Lilith data. For LCSim data and shallower transits in Lilith data, either no scaling led to better results than sigma scaling, or no clear distinguishment could be made.

In line with \cite{pearson2018searching}, it was shown that detrending is not necessary for the algorithm to work, as opposed to for example the BLS algorithm \cite{kovacs2002box}. Nevertheless, a positive effect was observed when low-risk detrending was applied to remove only large-scale stellar variability, with the goal of making the input ranges to the network more consistent. Centroid data also seemed to help the network in distinguishing background patterns from data points belonging to transit signals. \todo{cite centroid inputs}

In addition to preprocessing, the network architecture and training also take part in our question of how the RNN should be applied for our task. It was shown how using different weighting parameters in the network's loss function can help finetune the network on the unbalanced training data which we are dealing with. For example, it was found that by adding a small positive weight to all data points belonging to transit signals, one can optimize the trade-off between precision and recall at any given classification threshold. We expect that this weight helps to increase the noise floor in the PTS for a given light curve, which we found to be higher for LCSim data than for Lilith data in several cases. Since the noise in the PTS may still contain relevant information about the presence of potential signals, a larger positive weight for Lilith data may have resulted in higher recall for the RNN-based detection algorithms. A transit-specific weight was also adopted, with the desired effect of balancing the network's focus of learning to detect transit signals of varying depths. Nevertheless, slight changes to these parameters may lead to better results in different data sets, and we therefore re comment to tune them to the data at hand.

Regarding the network architecture, we opted for a relatively simple design. In the first place, this was to illustrate that this task does not require a highly complex network architecture. In addition, a simple architecture would allow for easier reproduction of the work. During the process of comparing architectures, in fact we found that simpler architectures led to better results than more complex ones. For example, GRU produced better and more stable results than LSTM, while having less parameters. Furthermore, a network with multiple recurrent layers performed slightly worse than the simpler network with only one layer. Including bidirectionality in the RNN on the other hand, led to a great improvement in the results. The confidence RNN was only slightly more complex than the basis network, but also led to worse results.

The question of whether RNNs provide an efficient and competitive alternative to existing approaches was investigated in three real-world problems. In terms of efficiency, neural networks in general were expected to be appealing compared to the common brute-force approach that is taken to search for transits. The computation times observed in the experiments for Mono-BLS and BLS compared to our RNN-based approach were in line with this expectation. Among different types of NNs, RNN is known to be less efficient than the CNN, due to its recurrent structure. However, since CNNs are required to be applied multiple times to the same light curve in the task of transit detection \cite{pearson2018searching}, this difference becomes smaller. A comparison of efficiency between the CNN and RNN has not been made in this work,  because many different design choices of this way of using the CNN could lead to different results. For typical TESS light curves of 27.4 days, our RNN was able to compute the PTS in under one second for over 50 light curves at once. This is reassuring, because the data sets that are currently produced by TESS and in the future by PLATO require efficient algorithms. The most time was taken by the method which determines the periodicity of candidate signals using the PTS. In this task, PTS-Fold led to more correct detections than PTS-Peak, but PTS-Peak outperformed PTS-Fold in terms of efficiency by at least one order of magnitude. This is because PTS-Fold tends more towards a blind search, while PTS-Peak is guided by the detection of individual events in the PTS. If the search is directed towards monotransits, however, we do not require PTS-Fold or PTS-Peak, and the PTS can directly be used to set detection thresholds. For this reason, the search for monotransits in large data sets can be conducted in minutes using an RNN.

Not only in terms of efficiency, but also in terms of detection performance, the RNN showed most potential in the case of monotransits. We found it to be more robust against transit-resembling noise patterns than a box-fitting approach. This is likely because it was specifically trained on individual transit signals, and not on aggregated or folded light curves. It therefore does not rely on periodicities of signals the way BLS does. BLS uses periodicities to its advantage by aggregating multiple transits in the same light curve, effectively increasing the SNR of the signal. We expect this to be the reason that BLS was still dominant in the case of repeating signals. Nevertheless, we found multiple examples of where BLS failed to detect a planet, while the RNN was able to detect it. Some of these cases showed to be highly noisy light curves with noise patterns at time scales similar to the transit signal. In these cases, detrending may be the limiting factor for BLS to detect the planets. Since the RNN does not require detrending, it may still distinguish the signals from the distracting background.

Lastly, two approaches were evaluated to increase the interpretability of the RNN. Although true uncertainties are difficult to obtain, we attempted to let the RNN output an indication of its confidence over given outputs. Visually, the results were as we would expect: in noisy regions of a light curve the confidence was often slightly reduced, even though the standard outputs remained the same; in the case of a transit signal, the confidence would be low at ingress and egress, indicating that the network is not certain when exactly the transit starts and ends. However, in some cases the confidence outputs $c$ were approximately the same as $y$ mirrored, i.e. $y = 1-c$. We expect this to be the reason why we did not observe differences in the performance if the confidence outputs were or were not used in the task of monotransit detection.

Another attempt of increasing the interpretability of the RNN outputs, involved the use of learned representations of signals. We only provided an illustration of how these representations may be used to resolve ambiguities, but the few examples that were evaluated showed intuitive results. The standard outputs of the RNN provide only limited information. Any increase in the PTS may indicate the presence of a transit signal, but sometimes it is not clear what triggers the response of the RNN. Moreover, the connection between two peaks in the PTS can only be based on their duration. Learned representations could open the door to understanding better what caused the RNN to output a certain value, by comparing its representations at a different moments in time.  In addition, as was shown here, they can be used to separate the detection of signals from different planets. However, more research needs to be conducted to evaluate the effectiveness of this approach.
