
\section{Answers to research questions}

Although this work is based on simulated data, the results achieved on both LCSim and Lilith data show that RNNs have promising capability of performing well in the task of transit detection. The question of how RNNs should be applied for this task was investigated in several experiments. Different preprocessing steps were evaluated, including the way data gaps are handled and the way input data is scaled. RNNs come with the possibility of predicting missing values in a light curve. However, we found that a simple gap-filling approach such as linear interpolation can lead to similar results in terms of the average precision (AP) of classifying individual data points as signal or non-signal, while requiring about five times less computation time. Furthermore, it was shown that using zero-filling for gaps in Lilith data can result in an increase of up to 0.02 AP using our data sets, compared to using linear interpolation. Possibly, zero-filling allows the network to better distinguish imputed data points from real ones, such that it takes into account the fact that they were missing from the original light curve. In literature concerning transit detection, the effect of missing data on the performance of neural networks was only touched upon by \cite{pearson2018searching}, however no methods were evaluated to deal with this problem. The approach of feeding the network time differences between measurements as additional inputs, as taken by \cite{naul2018recurrent} and \cite{becker2020scalable}, has yet to be evaluated in the task of transit detection.

Regarding the scaling of light curves prior to applying the RNN, we expected that scaling light curves by their estimated white noise level would be beneficial to the network. Namely, we would argue that by removing the variance in white noise, the transit signal would stand out more. However, the results showed that this sort of scaling, which we referred to as sigma scaling, was only beneficial for the deepest transit signals in Lilith data. In that case a difference of up to 0.1 AP was observed for the two scaling approaches. For LCSim data and shallower transits in Lilith data, either no scaling led to slightly better results than sigma scaling, or no clear distinction could be made due to the spread in the results.

Similar to \cite{pearson2018searching}, it was shown that our algorithm does not require detrending to work, as opposed to for example the BLS algorithm \cite{kovacs2002box}. Nevertheless, a small positive effect, i.e. an increase of $\sim$0.015 AP, was observed when low-risk detrending was applied to remove only large-scale stellar variability in Lilith data, with the goal of making the input ranges to the network more consistent. Centroid data also seemed to help the network in distinguishing background patterns from data points belonging to transit signals, which is in line with the results from \cite{osborn2020rapid} and \cite{morvan2020detrending}, but this effect was smaller. However, a relatively large spread in the results restricts us from making hard conclusions.

In addition to preprocessing, the network architecture and training also took part in our question of how the RNN should be applied for our task. It was shown how using different weighting parameters in the network's loss function can help finetune the network on the unbalanced training data which we are dealing with. For example, it was found that by adding a small positive weight to all data points belonging to transit signals, one can optimize the trade-off between precision and recall at any given classification threshold. We expect that this weight helps to increase the noise floor in the PTS for a given light curve, which we found to be higher for LCSim data than for Lilith data in several cases. Since the noise in the PTS may still contain relevant information about the presence of potential signals, a larger positive weight for Lilith data may have resulted in higher recall for the RNN-based detection algorithms. A transit-specific weight was also adopted, with the desired effect of balancing the network's focus of learning to detect transit signals of varying depths. Nevertheless, slight changes to these parameters may lead to better results in different data sets, and we therefore recommend tuning them to the data at hand.

Regarding the network architecture, we opted for a relatively simple design. In the first place, this was to illustrate that this task does not require a highly complex network architecture. In addition, a simple architecture would allow for easier reproduction of the work. During the process of comparing architectures, in fact we found that simpler architectures led to better results than more complex ones. For example, GRU produced better and more stable results than LSTM, while having less parameters. Furthermore, a network with multiple recurrent layers performed slightly worse than the simpler network with only one layer. Including bidirectionality in the RNN on the other hand, led to an improvement in the results, e.g. in the case of classifying light curve segments it led to an increase of accuracy of $\sim$0.04. The confidence RNN was only slightly more complex than the basis network, but led to worse results, as was shown in the monotransit experiment. This is contrary to the results of \cite{devries2018learning}, who did not observe a decrease in performance if a confidence branch is used in the network.

The question of whether RNNs provide an efficient and competitive alternative to existing approaches was investigated in three real-world transit detection problems. In terms of efficiency, neural networks in general were expected to be appealing compared to the common brute-force approach that is taken to search for transits. The computation times observed in the experiments for Mono-BLS and BLS compared to our RNN-based approach were in line with this expectation. Among different types of NNs, the RNN is known to be less efficient than the CNN, due to its recurrent structure. However, since CNNs are required to be applied multiple times to the same light curve in the task of transit detection \cite{pearson2018searching}, this difference becomes smaller. A comparison of efficiency between the CNN and RNN was not made in this work, because many different design choices of this way of using the CNN could lead to different results. For typical TESS light curves of 27.4 days, our RNN was able to compute the PTS in under one second for over 50 light curves at once. This is reassuring, because the data sets that are currently produced by TESS and in the future by PLATO require efficient algorithms. The most time was taken by the method which determines the periodicity of candidate signals using the PTS. In this task, PTS-Fold led to more correct detections than PTS-Peak, but PTS-Peak outperformed PTS-Fold in terms of efficiency by at least one order of magnitude. This is because PTS-Fold tends more towards a blind search, while PTS-Peak is guided by the detection of individual events in the PTS. If the search is focused on monotransits, however, PTS-Fold or PTS-Peak are not needed, and the PTS can directly be used to set detection thresholds. For this reason, the search for monotransits in large data sets could be conducted in minutes when using an RNN.

Not only in terms of efficiency, but also in terms of detection performance, the RNN showed most potential in the case of monotransits. We found it to be more robust against transit-resembling noise patterns than a box-fitting approach in several examples. This is likely because it was specifically trained on individual transit signals, and not on aggregated or folded light curves. It therefore does not rely on periodicities of signals the way BLS does. BLS uses periodicities to its advantage by aggregating multiple transits in the same light curve, effectively increasing the SNR of the signal. We expect this to be the reason that BLS was still dominant in the case of repeating signals. Nevertheless, we found multiple examples of where BLS failed to detect a planet, while the RNN was able to detect it. Some of these cases showed to be highly noisy light curves with noise patterns at time scales similar to the transit signal. In these cases, detrending may be the limiting factor for BLS to detect the planets. Since the RNN does not require detrending, it may still distinguish the signals from the distracting background.

Lastly, two approaches were evaluated to increase the interpretability of the RNN. Although true uncertainties are difficult to obtain, we attempted to let the RNN output an indication of its confidence over given outputs. Visually, the results were as we would expect: in noisy regions of a light curve the confidence was often slightly reduced, even though the standard outputs remained the same; in the case of a transit signal, the confidence would be low at ingress and egress, indicating that the network is not certain when exactly the transit starts and ends. However, in some cases we noticed the confidence outputs $c$ to be approximately the same as $y$ mirrored, i.e. $y = 1-c$. We expect this to be the reason why we did not observe differences in the performance if the confidence outputs were or were not used in the task of monotransit detection. Moreover, since the overall performance of the network with confidence outputs was degraded compared to the basis network, the confidence network proved not to be beneficial in our task.

Another attempt of increasing the interpretability of the RNN outputs involved the use of learned representations of signals. We only provided an illustration of how these representations may be used to resolve ambiguities, but the few examples that were evaluated showed intuitive results. The standard outputs of the RNN provide only limited information. Any increase in the PTS may indicate the presence of a transit signal, but sometimes it is not clear what triggers the response of the RNN. Moreover, the connection between two peaks in the PTS can only be based on their duration. Learned representations could increase our understanding of what caused the RNN to output a certain value, by comparing its representations at different moments in time. In addition, as was shown in this work, they could be used to separate the detection of signals from different planets. However, more research needs to be conducted to evaluate the effectiveness of this approach.
